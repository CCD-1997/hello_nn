{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "###### MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the mmist dataset from tensorflow.examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist_data = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_image_width = 28\n",
    "n_image_height = 28\n",
    "n_input_pixels = n_image_height * n_image_width\n",
    "filter_width = 5\n",
    "filter_height = 5\n",
    "n_classes = 10  # digits 0-9\n",
    "n_channels = 1  # black\n",
    "\n",
    "con_1_features = 16\n",
    "con_2_features = 32\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input/Output Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_input_pixels])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer Weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_lay_1 = {\n",
    "    'weight': tf.Variable(\n",
    "        tf.random_normal([filter_height, filter_width, n_channels, con_1_features], stddev=0.1)),\n",
    "    'bias': tf.Variable(tf.random_normal([con_1_features], stddev=0.1))\n",
    "}\n",
    "conv_lay_2 = {\n",
    "    'weight': tf.Variable(\n",
    "        tf.random_normal([filter_height, filter_width, con_1_features, con_2_features], stddev=0.1)),\n",
    "    'bias': tf.Variable(tf.random_normal([con_2_features], stddev=0.1))\n",
    "}\n",
    "fc_nn_lay_1 = {\n",
    "    'weight': tf.Variable(\n",
    "        tf.random_normal([7 * 7 * con_2_features, n_classes], stddev=0.1)),\n",
    "    'bias': tf.Variable(tf.random_normal([n_classes], stddev=0.1))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resize image to proper shape\n",
    "x_img = tf.reshape(X, [-1, n_image_width, n_image_height,\n",
    "                       n_channels])  # [batch, height, width, channels]\n",
    "\n",
    "h_conv_1 = tf.nn.conv2d(x_img, conv_lay_1['weight'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "h_relu_1 = tf.nn.relu(h_conv_1 + conv_lay_1['bias'])\n",
    "op_pool_1 = tf.nn.max_pool(h_relu_1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "h_conv_2 = tf.nn.conv2d(op_pool_1, conv_lay_2['weight'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "h_relu_2 = tf.nn.relu(h_conv_2 + conv_lay_2['bias'])\n",
    "op_pool_2 = tf.nn.max_pool(h_relu_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "flat_lay_3 = tf.reshape(op_pool_2, [-1, 7 * 7 * con_2_features])\n",
    "\n",
    "h_nn_1 = tf.matmul(flat_lay_3, fc_nn_lay_1['weight']) + fc_nn_lay_1['bias']\n",
    "final_op = tf.nn.sigmoid(h_nn_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean-squared error\n",
    "error = tf.reduce_mean(0.5 * tf.square(final_op - Y))\n",
    "\n",
    "# adam-optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(final_op, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Train ***********\n",
      "Batch: 0 validation-error = 0.208108 accuracy = 6.000000\n",
      "Batch: 100 validation-error = 0.027116 accuracy = 69.999999\n",
      "Batch: 200 validation-error = 0.018338 accuracy = 72.000003\n",
      "Batch: 300 validation-error = 0.021567 accuracy = 68.000001\n",
      "Batch: 400 validation-error = 0.010519 accuracy = 86.000001\n",
      "Batch: 500 validation-error = 0.010969 accuracy = 83.999997\n",
      "Batch: 600 validation-error = 0.008034 accuracy = 81.999999\n",
      "Batch: 700 validation-error = 0.004340 accuracy = 98.000002\n",
      "Batch: 800 validation-error = 0.007647 accuracy = 94.000000\n",
      "Batch: 900 validation-error = 0.001807 accuracy = 98.000002\n",
      "Batch: 1000 validation-error = 0.003638 accuracy = 94.000000\n",
      "*********** Test ***********\n",
      "Final Accuracy = 96.820003\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    print(\"*********** Train ***********\")\n",
    "\n",
    "    train_examples = len(mnist_data.train.images)\n",
    "\n",
    "    for i in range(train_examples // batch_size):\n",
    "        train_batch = mnist_data.train.next_batch(batch_size)\n",
    "        _, err = sess.run([optimizer, error], feed_dict={X: train_batch[0], Y: train_batch[1]})\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            validation_batch = mnist_data.validation.next_batch(batch_size)\n",
    "            acc = accuracy.eval({X: validation_batch[0], Y: validation_batch[1]})\n",
    "            print(\"Batch: %d validation-error = %f accuracy = %f\" % (i, err, acc * 100))\n",
    "\n",
    "    print(\"*********** Test ***********\")\n",
    "\n",
    "    acc = accuracy.eval({X: mnist_data.test.images, Y: mnist_data.test.labels})\n",
    "    print(\"Final Accuracy = %f\" % (acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
