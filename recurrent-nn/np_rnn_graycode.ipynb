{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network\n",
    "###### Graycode using numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seed random number generator\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_test_cases = 100\n",
    "train_test_ratio = 0.80\n",
    "\n",
    "tmp_list = []\n",
    "features = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to generate graycode of number given bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graycode(x, mx):\n",
    "    return int(bin(mx + x ^ int(x / 2))[3:], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate data (graycode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(total_test_cases):\n",
    "    a = np.random.randint(0, 256)\n",
    "    b = graycode(a, 256)\n",
    "\n",
    "    features.append(a)\n",
    "    labels.append(b)\n",
    "\n",
    "features = np.array(features, dtype=np.uint8).reshape(-1, 1)\n",
    "labels = np.array(labels, dtype=np.uint8).reshape(-1, 1)\n",
    "features = np.unpackbits(features, axis=1)\n",
    "labels = np.unpackbits(labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into train-test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train = np.array(features[:int(train_test_ratio * len(features))])\n",
    "features_test = np.array(features[int(train_test_ratio * len(features)):])\n",
    "\n",
    "labels_train = labels[:int(train_test_ratio * len(labels))]\n",
    "labels_test = labels[int(train_test_ratio * len(labels)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input_layers = 1\n",
    "n_hidden_layers = 16\n",
    "n_output_layers = 1\n",
    "n_sequence = 8\n",
    "\n",
    "learning_rate = 1\n",
    "\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation functions and their derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activation_f = {\n",
    "    'identity': lambda f_x: f_x,\n",
    "    'sigmoid': lambda f_x: 1.0 / (1.0 + np.exp(-f_x)),\n",
    "    'tanh': lambda f_x: np.tanh(f_x),\n",
    "    'arctan': lambda f_x: np.arctan(f_x),\n",
    "    'relu': lambda f_x: f_x * (f_x > 0),\n",
    "    'softplus': lambda f_x: np.log(1 + np.exp(f_x)),\n",
    "    'sinusoid': lambda f_x: np.sin(f_x),\n",
    "    'gaussian': lambda f_x: np.exp(-f_x * f_x)\n",
    "}\n",
    "activation_f_prime = {\n",
    "    'identity': lambda f_dx: 1,\n",
    "    'sigmoid': lambda f_dx: f_dx * (1.0 - f_dx),\n",
    "    'tanh': lambda f_dx: 1.0 - f_dx**2,\n",
    "    'arctan': lambda f_dx: 1.0 / (1.0 + np.tan(f_dx)**2),\n",
    "    'relu': lambda f_dx: 1.0 * (f_dx > 0),\n",
    "    'softplus': lambda f_dx: 1.0 - np.exp(-f_dx),\n",
    "    'sinusoid': lambda f_dx: np.cos(np.arcsin(f_dx)),\n",
    "    'gaussian': lambda f_dx: -2 * f_dx * np.sqrt(-np.log(f_dx))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation function parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = 'sigmoid'\n",
    "f2 = 'sigmoid'\n",
    "\n",
    "act_f1 = activation_f[f1]\n",
    "act_f2 = activation_f[f2]\n",
    "\n",
    "act_f1_prime = activation_f_prime[f1]\n",
    "act_f2_prime = activation_f_prime[f2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V = np.random.normal(scale=0.1, size=(n_input_layers, n_hidden_layers))\n",
    "W = np.random.normal(scale=0.1, size=(n_hidden_layers, n_output_layers))\n",
    "R = np.random.normal(scale=0.1, size=(n_hidden_layers, n_hidden_layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## TRAIN ##########\n",
      "Epoch: 0 Error: 0.141120\n",
      "Epoch: 10 Error: 0.006129\n",
      "Epoch: 20 Error: 0.000559\n",
      "Epoch: 30 Error: 0.000238\n",
      "Epoch: 40 Error: 0.000142\n",
      "Epoch: 50 Error: 0.000100\n",
      "Epoch: 60 Error: 0.000076\n",
      "Epoch: 70 Error: 0.000062\n",
      "Epoch: 80 Error: 0.000052\n",
      "Epoch: 90 Error: 0.000044\n"
     ]
    }
   ],
   "source": [
    "print(\"########## TRAIN ##########\")\n",
    "\n",
    "# Training-set\n",
    "X = features_train\n",
    "Y = labels_train\n",
    "\n",
    "# Epoch-training\n",
    "for e in range(n_epochs):\n",
    "\n",
    "    E = 0\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "\n",
    "        err = 0\n",
    "\n",
    "        V_update = np.zeros_like(V)\n",
    "        W_update = np.zeros_like(W)\n",
    "        R_update = np.zeros_like(R)\n",
    "\n",
    "        h_layers = [np.zeros((1, n_hidden_layers))]\n",
    "\n",
    "        dels = []\n",
    "\n",
    "        # Forward Pass\n",
    "        for j in range(n_sequence):\n",
    "            # Forward Prop\n",
    "            x = np.array(X[i][j])\n",
    "            y = np.array(Y[i][j])\n",
    "\n",
    "            h_inter = np.dot(x, V) + np.dot(h_layers[-1], R)\n",
    "            h_final = act_f1(h_inter)\n",
    "            o_inter = np.dot(h_final, W)\n",
    "            o_final = act_f2(o_inter)\n",
    "\n",
    "            # Store hidden layer\n",
    "            h_layers.append(h_final)\n",
    "\n",
    "            err += (0.5 * np.square(y - o_final))[0][0]\n",
    "\n",
    "            # Backward Prop\n",
    "            del_h_o = -np.multiply(y - o_final, act_f2_prime(o_final))\n",
    "\n",
    "            # Store delta\n",
    "            dels.append(del_h_o)\n",
    "\n",
    "            change_h_o = np.dot(h_final.T, del_h_o)\n",
    "            W_update += change_h_o\n",
    "\n",
    "        next_del = np.zeros(n_hidden_layers)\n",
    "\n",
    "        # Backward Propagation through time\n",
    "        for j in range(n_sequence):\n",
    "            x = np.array(X[i][-j - 1])\n",
    "\n",
    "            del_h = (np.dot(next_del, R.T) + np.dot(dels[-j - 1], W.T)) * act_f1_prime(h_layers[-j - 1])\n",
    "\n",
    "            change_h_h = np.dot(h_layers[-j - 2].T, del_h)\n",
    "            change_i_h = np.dot(x.T, del_h)\n",
    "\n",
    "            R_update += change_h_h\n",
    "            V_update += change_i_h\n",
    "\n",
    "            next_del = del_h\n",
    "\n",
    "        E += err / n_sequence\n",
    "\n",
    "        # Adjust Weights\n",
    "        V -= V_update * learning_rate\n",
    "        W -= W_update * learning_rate\n",
    "        R -= R_update * learning_rate\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        print(\"Epoch: %d Error: %f\" % (e, E / X.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## TEST ##########\n",
      "15 => 8 \t -->  True \n",
      "64 => 96 \t -->  True \n",
      "196 => 166 \t -->  True \n",
      "25 => 21 \t -->  True \n",
      "111 => 88 \t -->  True \n",
      "226 => 147 \t -->  True \n",
      "215 => 188 \t -->  True \n",
      "135 => 196 \t -->  True \n",
      "26 => 23 \t -->  True \n",
      "153 => 213 \t -->  True \n",
      "104 => 92 \t -->  True \n",
      "22 => 29 \t -->  True \n",
      "9 => 13 \t -->  True \n",
      "195 => 162 \t -->  True \n",
      "231 => 148 \t -->  True \n",
      "126 => 65 \t -->  True \n",
      "23 => 28 \t -->  True \n",
      "125 => 67 \t -->  True \n",
      "100 => 86 \t -->  True \n",
      "155 => 214 \t -->  True \n",
      "\n",
      "Success: 20/20, Accuracy = 100.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"########## TEST ##########\")\n",
    "\n",
    "# Test-set\n",
    "X = features_test\n",
    "Y = labels_test\n",
    "\n",
    "success = 0\n",
    "\n",
    "# Start Test\n",
    "for i in range(X.shape[0]):\n",
    "\n",
    "    a = np.packbits(X[i])[0]\n",
    "    b = np.packbits(Y[i])[0]\n",
    "\n",
    "    c = []\n",
    "\n",
    "    h_layer = np.zeros((1, n_hidden_layers))\n",
    "\n",
    "    for j in range(n_sequence):\n",
    "        x = np.array(X[i][j])\n",
    "        y = np.array(Y[i][j])\n",
    "\n",
    "        # Forward prop\n",
    "        h_inter = np.dot(x, V) + np.dot(h_layer, R)\n",
    "        h_final = act_f1(h_inter)\n",
    "        o_inter = np.dot(h_final, W)\n",
    "        o_final = act_f2(o_inter)\n",
    "\n",
    "        h_layer = h_final\n",
    "\n",
    "        c.append((o_final > 0.5).astype(int)[0][0])\n",
    "\n",
    "    c = np.packbits(c)[0]\n",
    "\n",
    "    if b == c:\n",
    "        success += 1\n",
    "\n",
    "    print(\"%d => %d \\t --> %5s \" % (a, c, b == c))\n",
    "\n",
    "print(\"\\nSuccess: %d/%d, Accuracy = %f\" % (success, X.shape[0], success / X.shape[0] * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
